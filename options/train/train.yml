#### Conv-TasNet Setting
name: Conv_Tasnet
# gpu_ids: [0,1,2,3,6,7]
gpu_ids: [0,1,2,3]
world_size: 1
epochs: 100

#### Dataset Configure
datasets:
  num_workers: 4
  batch_size: 24
  fs: 16000
  chunk_size: 32000 #### fs*chunk_len
  train:
    mix_scp: /star-home/jinzengrui/dev/espnet/egs2/librimix/enh1_medium/data/train_medium_2_mix/mix.scp
    ref_scp: 
      # - /star-home/jinzengrui/dev/espnet/egs2/librimix/enh1_medium/data/train_medium_2_mix_truncated_filtered/spk1.scp
      # - /star-home/jinzengrui/dev/espnet/egs2/librimix/enh1_medium/data/train_medium_2_mix_truncated_filtered/spk2.scp
      - /star-home/jinzengrui/dev/espnet/egs2/librimix/enh1_medium/data/train_medium_2_mix/spk1.scp
      - /star-home/jinzengrui/dev/espnet/egs2/librimix/enh1_medium/data/train_medium_2_mix/spk2.scp
    segments: /star-home/jinzengrui/data/LibriheavyCSS/segments_train_medium
    sr: 16000
  val:
    mix_scp: /star-home/jinzengrui/dev/espnet/egs2/librimix/enh1_medium/data/dev_2_mix/mix.scp
    ref_scp: 
      - /star-home/jinzengrui/dev/espnet/egs2/librimix/enh1_medium/data/dev_2_mix/spk1.scp
      - /star-home/jinzengrui/dev/espnet/egs2/librimix/enh1_medium/data/dev_2_mix/spk2.scp
    segments: /star-home/jinzengrui/data/LibriheavyCSS/segments_dev
    sr: 16000

#### training settings: learning rate scheme, loss
train:
  optimizer: adam
  min_lr: !!float 1e-8
  patience: 2
  factor: 0.5
  logging_period: 200
  clip_norm: 200
  num_epochs: 100
  checkpoint: Conv-TasNet-new-segments

optimizer_kwargs:
  lr: !!float 1e-3
  weight_decay: !!float 1e-5

#### network configure
net_conf:
  N: 512
  L: 16
  B: 128
  H: 512
  P: 3
  X: 8
  R: 3
  norm: gln
  num_spks: 2
  activate: relu
  causal: false
  ##skip_con: false

#### resume model
resume:
  path: /star-home/jinzengrui/dev/Conv-TasNet/Conv_TasNet_Pytorch
  resume_state: false
